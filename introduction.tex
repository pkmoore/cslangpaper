\section{Introduction}
\label{SEC:introduction}

%H. Dornhackl, K. Kadletz, R. Luh and P. Tavolato,
% "Defining Malicious Behavior,"
%2014 Ninth International Conference on Availability,
%Reliability and Security, Fribourg, Switzerland, 2014,
%pp. 273-278, doi: 10.1109/ARES.2014.43.
% Using a formal model to encode some sort of desired behavior

{\textit ``Actions speak louder than words...'' - Unknown}

It is a well established principle
that, in the wake of a failure,
monitoring and examining the actions
of an application
during execution can provide valid insight
into the root cause.
Taking advantage of such information
can aid in correcting
the cause of failure
and assist in the creation
of tests to ensure
that those causes
are not repeated in the future.
The challenge is in
how to identify and extract this data
from large and detailed sources like application logs,
system call traces,
or application recordings.
Central to this problem
is accurately describing what activity is important
and what to do when you find it.
% This paper covers our efforts to make this process easier.

In addressing this difficulty,
we drew inspiration from two sources.
The first is
the great amount of literature
supporting the use of event
processing techniques over large streams of data, such as
industrial control system sensor readings,
transaction processing software,
and networking monitoring systems.
We argue that the techniques these tools use
to identify problems in a manufacturing environment,
network outages,
or patterns in customer behavior
can be applied
to large application activity streams to accurately
and efficiently recognize target sequences.
The second is a recent successful effort
to identify bugs by monitoring
and modifying an application's interactions with its environment.
This work demonstrated that specific properties
visible in the results of system calls
made by a failing application
could be captured and applied
to the results of other applications
to see how it would fare under the same circumstances.

Building upon these successes,
we introduce a tool
that applies event processing techniques
to the identification
of behaviors carried out by an application
that could interfere with its successful operation.
What makes this possible is CSlang,
a new domain specific language
for describing these behaviors.
These descriptions are then used
to search a recording of an application's system calls,
remote procedure calls,
or other actions in order to determine if it has
performed what was described.
This capability is useful
for ensuring an application executed a desired behavior
or avoided an undesired one
depending on the user's need.
Further, CSlang permits
its user to describe a set of modifications
to be made to an activity sequence should it be encountered.
By combining passive monitoring and active modification
of an application's activity,
CSlang aids in identifying environmental bugs
that may be missed by other testing strategies.

This combined approach is made possible
by compiling a CSlang program
into a transducer
that operates on principles similar
to a standard finite-state transducer.
That is,
according to the rules laid down in its CSlang program,
the transducer consumes an input sequence of activity
to determine if the desired pattern is present,
while simultaneously producing an output stream.
The results of this are twofold.
If the transducer accepts the input sequence
it means the described activity is present which,
depending on the nature of the sequence
may indicate the existence of a bug.
In cases where acceptance indicates an opportunity
for more detailed testing,
the modified output sequence may be used
to drive a simulation (as with the earlier work on environmental bugs)
to evaluate an application's response to the simulated scenario
or to populate a test suite.

We created a prototype implementation of CSlang
and initially tested it by
re-treading proven ground.
This involved reimplementing the ``anomalies''
described in earlier work on the SEA technique~\cite{crashsim}.
Side-by-side comparison shows that our new
descriptions are dramatically more concise (up to XXX\% in some cases)
than their original counterparts.
This makes them
more readable
and maintainable.
In this way, CSlang increases the applicability of the SEA technique
by expanding its use to a wider audience.

Next, we wanted to
show that CSlang
could be used on activity streams
other than system calls.
To do so,
we exploited the ease with which
CSlang can be augmented
to consume new input formats
by adding support for two remote procedure call formats -- JSONRPC and XMLRPC.
These formats were chosen
because they are popular,
and well supported and are
used by many major applications.
Taking advantage of these new input formats,
we wrote programs
that could identify opportunities
to modify the results of RPC calls.
The output from these programs was used to populate a test suite
for each application.
When executed, these test suites identified AAA new bugs in the tested applications.

The main contributions in this work can be summarized as follows:

\begin{itemize}

\item{We create a new language, {\em CSLang},
  which allows for concise, but expressive, descriptions of
    application activity and the action to take should this activity arise}

\item{We show how CSlang can be used make employing the SEA technique easier}

\item{We illustrate the ease with which CSLang can be extended by modifying
  it to accept variety of communication protocols}

\end{itemize}

