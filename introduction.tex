\section{Introduction}
\label{SEC:introduction}

%H. Dornhackl, K. Kadletz, R. Luh and P. Tavolato,
% "Defining Malicious Behavior,"
%2014 Ninth International Conference on Availability,
%Reliability and Security, Fribourg, Switzerland, 2014,
%pp. 273-278, doi: 10.1109/ARES.2014.43.
% Using a formal model to encode some sort of desired behavior

{\textit ``Actions speak louder than words...'' - Unknown}


It is a well established principle
that, in the wake of a failure,
monitoring and examining the actions
of an application
during execution can provide valid insight
into the root cause.
Taking advantage of such information
can aid not only in correcting
the cause of failure,
but also assist in the creation
of tests to ensure
that those causes
are not repeated in the future.
The challenge is in
how to identify and extract this data
from large and detailed sources like application logs,
system call traces,
or application recordings.
Central to this problem
is accurately describing what activity is important
and what to do when you find it.
% This paper covers our efforts to make this process easier.

In addressing this difficulty, we drew inspiration from two sources. The
first is a recent study that confirmed the value of monitoring and
modifying an applicationâ€™s interactions with its environment. That study,
which introduced the SEA technique, demonstrated that specific properties
visible in the results of system calls made by a failing application could
be captured and simulated for testing against other applications.  The
second was the great amount of literature supporting the use of event
processing techniques over large streams of data, such as industrial
control system sensor readings, transaction processing software, and
networking monitoring systems. We posited that the techniques these tools
use to identify problems in a manufacturing environment, patterns in
network outages, or customer behavior, could be applied to large
application activity streams to accurately and efficiently recognize target
sequences.


Building upon these successes,
we introduce a tool
that utilizes event processing techniques
to identify
behaviors carried out by an application
that may cause it to fail.
What makes this possible is PORT
(\textbf{P}attern \textbf{O}bservation, \textbf{R}ecognition, and
\textbf{T}ransformation)
a new domain specific language
created to describe these behaviors.
These descriptions are then used
to search a recording of an application's actions
across a variety of ``activity representations,''
such as system calls,
or remote procedure calls.
This capability is useful
for ensuring an application executed a desired behavior
or avoided an undesired one.
Further, PORT can describe
a set of modifications
that should be made
if a particular activity sequence is encountered.
By combining passive monitoring and active modification
of an application's activity,
PORT can aid in identifying bugs
that may be missed by other testing strategies.

PORT's passive and active capabilities are made possible
by compiling a PORT program
into a mutator
that operates on principles similar
to a standard finite-state transducer.
That is,
according to the rules laid down in its source program,
the mutator will consume an input sequence of activity
to determine if a particular pattern is present,
while simultaneously producing an output stream.
If the mutator accepts the input sequence
it means the described activity is present.
In some cases,
this may directly indicate
the existence of a bug.
In other cases,
the pattern may
indicate an opportunity
for more detailed testing
where the modified output sequence is used
to evaluate an application's response to a simulated scenario.

We first evaluate the effectiveness of the above technique
by creating a prototype implementation of PORT
and using it to
reimplement the ``anomalies''
described in earlier work on the SEA technique~\cite{DBLP:conf/issre/MooreCFW19}.
This technique used system call recordings
to expose an application to situations that had caused another to fail.
Side-by-side comparison shows that our new
descriptions are more concise,
readable,
and maintainable
than their original counterparts.
As an added benefit,
PORT can expand the use of the SEA technique,
which has already been proven
to be an effective bug detector,
by facilitating its use
on a wider variety of applications and activity formats.

Next, we
deterined how well PORT
supports activity streams
other than system calls.
To do so,
we exploited the ease with which
PORT can be augmented
to consume new activity representations
by adding support for two remote procedure call formats -- JSONRPC and XMLRPC.
Taking advantage of these new activity representations,
we wrote programs that operate on activity sequences such as those
used as examples in the formats respective specifications.
This effort
showed that PORT is both quick and easy to extend largely thanks to its
use of a generic intermediate data format.

Finally, we demonstrate that PORT can also be used for applications other than software testing.
Specifically, we sketch how a model used for
detecting malicious behavior in Windows applications due to Dornhackl et al.~\cite{Dornhackl2014} can be implemented in PORT.
%This plan details how PORT could be used to
%implement each of the components required by their technique.


The main contributions in this work can be summarized as follows:

\begin{itemize}

\item We present a domain specific language, {\em PORT},
  which allows for concise descriptions of checkers that can recognize patterns in
  an application's activity stream as well as transformers of such activity streams that can aid software testing.

\item We show how PORT can be used to make employing the SEA technique
  more widely applicable by finding bugs in more types of software.

\item We illustrate the ease with which PORT can be extended by modifying
  it to accept a variety of ``activity representations''.

\end{itemize}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
